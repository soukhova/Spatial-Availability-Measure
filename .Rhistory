idx <- which(od_ft$X1 == "TABLE    : emp_stat (Full time)")
od_ft <- od_ft %>%
slice((idx+2):n())
od_ft <- od_ft %>%
separate(X1, into = c("Zones", "Persons"), sep = " (?=[^ ]+$)") %>%
mutate(Zones = str_trim(Zones, side = "both")) %>%
separate(Zones, into = c("Origin", "Destination"), sep = " (?=[^ ]+$)") %>%
mutate(Origin = str_trim(Origin),
Destination = str_trim(Destination),
Persons = as.numeric(Persons))
workers_ft <- od_ft %>%
group_by(Origin) %>%
summarize(workers = sum(Persons),
.groups = "drop") %>%
transmute(GTA06 = Origin,
workers)
jobs_ft <- od_ft %>%
group_by(Destination) %>%
summarize(jobs = sum(Persons),
.groups = "drop") %>%
transmute(GTA06 = Destination,
jobs)
gtha_taz <- gtha_taz %>%
# Join workers
left_join(workers_ft,
by = "GTA06") %>%
# Join jobs
left_join(jobs_ft,
by = "GTA06") %>%
# Replace NAs with zeros
mutate(workers = replace_na(workers, 0),
jobs = replace_na(jobs, 0))
ggplot() +
geom_sf(data = gtha_taz,
aes(fill = workers),
color = NA) +
scale_fill_fermenter(direction = 1)
ggplot() +
geom_sf(data = gtha_taz,
aes(fill = jobs),
color = NA) +
scale_fill_fermenter(direction = 1)
gtha_taz_cent <- st_centroid(gtha_taz)
#workers (origins)
workers_ft_cent <- workers_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
work_origins <- cbind(workers_ft_cent, st_coordinates(st_transform(workers_ft_cent, crs = 4326))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>%
select(id, lon, lat) %>% as.data.frame()
#jobs (destinations)
jobs_ft_cent <- jobs_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
job_destinations <- cbind(jobs_ft_cent, st_coordinates(st_transform(jobs_ft_cent, crs = 4326))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>%
select(id, lon, lat) %>% as.data.frame()
save("work_origins", file = "data-inputs/Travel-Time-Calculations/inputs/work_origins.Rdata")
save("job_destinations", file = "data-inputs/Travel-Time-Calculations/inputs/job_destinations.Rdata")
#workers (origins)
workers_ft_cent <- workers_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
work_origins <- cbind(workers_ft_cent, st_coordinates(st_transform(workers_ft_cent, crs = 32617))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>%
select(id, lon, lat) %>% as.data.frame()
#jobs (destinations)
jobs_ft_cent <- jobs_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
job_destinations <- cbind(jobs_ft_cent, st_coordinates(st_transform(jobs_ft_cent, crs = 32617))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>%
select(id, lon, lat) %>% as.data.frame()
save("work_origins", file = "data-inputs/Travel-Time-Calculations/inputs/work_origins.Rdata")
save("job_destinations", file = "data-inputs/Travel-Time-Calculations/inputs/job_destinations.Rdata")
usethis::use_github()
library(disk.frame)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(httr)
library(knitr)
#install.packages("kableExtra", dependencies = TRUE) #installing kableExtra and dependencies as I was recieving errors
library(kableExtra)
#install.packages("devtools")
#install.packages("Rtools")
#devtools::install_github("https://github.com/hrbrmstr/lodes.git", dependencies = TRUE) # if you need to download
library(lodes)
library(progress)
library(purrr)
library(r5r)
library(sf)
library(stplanr)
library(tidycensus)
library(tidyr)
library(tmap)
library(zoo) # for rollapplyr
# setup for disk.frame
setup_disk.frame()
options(scipen = 999)
options(java.parameters = "-Xmx6G")
options(future.globals.maxSize = Inf)
tmap_mode("view")
load(file = "data-inputs/Travel-Time-Calculations/inputs/workers_origins.Rdata")
load(file = "data-inputs/Travel-Time-Calculations/inputs/work_origins.Rdata")
load(file = "data-inputs/Travel-Time-Calculations/inputs/job_destinations.Rdata")
# the r5r package requires Java Development Kit version 11, which can be downloaded from https://www.oracle.com/java/technologies/javase-jdk11-downloads.html
dir.create("data-inputs/Travel-Time-Calculations/r5_graph")
r5_path <- file.path("data-inputs/Travel-Time-Calculations/r5_graph")
downloading ontario osm in the correct format
#downloading ontario osm in the correct format
download.file(url = paste0("https://download.geofabrik.de/north-america/canada/ontario-latest.osm.pbf"),
destfile = file.path(r5_path, "osm.pbf"),
mode = "wb")
r5_ONT <- setup_r5(data_path = r5_path, verbose = FALSE)
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
View(job_destinations)
library(readxl)
library(sf)
library(tidyverse)
library(units)
gtha_taz <- st_read("data-inputs/OD-by-FT-Employment/tts06_83_region.shp")
gtha_taz <- gtha_taz %>%
st_transform(crs = 32617)
gtha_taz <- gtha_taz %>%
transmute(GTA06 = as.character(GTA06),
AREA = st_area(geometry) %>%
set_units(km^2) %>%
drop_units())
ghta_taz_id <- gtha_taz$GTA06
od_ft <- read_delim(file = "data-inputs/OD-by-FT-Employment/tts-2016-OD-FT-Employment.txt",
delim = "\t",
col_names = FALSE)
idx <- which(od_ft$X1 == "TABLE    : emp_stat (Full time)")
od_ft <- od_ft %>%
slice((idx+2):n())
od_ft <- od_ft %>%
separate(X1, into = c("Zones", "Persons"), sep = " (?=[^ ]+$)") %>%
mutate(Zones = str_trim(Zones, side = "both")) %>%
separate(Zones, into = c("Origin", "Destination"), sep = " (?=[^ ]+$)") %>%
mutate(Origin = str_trim(Origin),
Destination = str_trim(Destination),
Persons = as.numeric(Persons))
workers_ft <- od_ft %>%
group_by(Origin) %>%
summarize(workers = sum(Persons),
.groups = "drop") %>%
transmute(GTA06 = Origin,
workers)
jobs_ft <- od_ft %>%
group_by(Destination) %>%
summarize(jobs = sum(Persons),
.groups = "drop") %>%
transmute(GTA06 = Destination,
jobs)
gtha_taz <- gtha_taz %>%
# Join workers
left_join(workers_ft,
by = "GTA06") %>%
# Join jobs
left_join(jobs_ft,
by = "GTA06") %>%
# Replace NAs with zeros
mutate(workers = replace_na(workers, 0),
jobs = replace_na(jobs, 0))
ggplot() +
geom_sf(data = gtha_taz,
aes(fill = workers),
color = NA) +
scale_fill_fermenter(direction = 1)
ggplot() +
geom_sf(data = gtha_taz,
aes(fill = jobs),
color = NA) +
scale_fill_fermenter(direction = 1)
gtha_taz_cent <- st_centroid(gtha_taz)
#workers (origins)
workers_ft_cent <- workers_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
work_origins <- cbind(workers_ft_cent, st_coordinates(st_transform(workers_ft_cent, crs = 32617))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>% as.data.frame()  %>%
select(id, lon, lat) %>% as.data.frame()
#jobs (destinations)
jobs_ft_cent <- jobs_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
job_destinations <- cbind(jobs_ft_cent, st_coordinates(st_transform(jobs_ft_cent, crs = 32617))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>% as.data.frame()  %>%
select(id, lon, lat)
save("work_origins", file = "data-inputs/Travel-Time-Calculations/inputs/work_origins.Rdata")
save("job_destinations", file = "data-inputs/Travel-Time-Calculations/inputs/job_destinations.Rdata")
load(file = "data-inputs/Travel-Time-Calculations/inputs/work_origins.Rdata")
load(file = "data-inputs/Travel-Time-Calculations/inputs/job_destinations.Rdata")
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 160)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 120)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 60)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 30
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
job_destinations1 <- job_destinations[1:100,]
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations1,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations1,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations1,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2020-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations1,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")))
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
Orig_chunk <- get_chunk(origins_chunks, i)
View(origins_chunks)
View(Orig_chunk)
#workers (origins)
workers_ft_cent <- workers_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
work_origins <- cbind(workers_ft_cent, st_coordinates(st_transform(workers_ft_cent, crs = 4326))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>% as.data.frame()  %>%
select(id, lon, lat) %>% as.data.frame()
#jobs (destinations)
jobs_ft_cent <- jobs_ft %>% merge(gtha_taz_cent %>% select(GTA06), by="GTA06") %>% st_sf
job_destinations <- cbind(jobs_ft_cent, st_coordinates(st_transform(jobs_ft_cent, crs = 4326))) %>%
rename(lon = "X", lat = "Y", id = "GTA06") %>% as.data.frame()  %>%
select(id, lon, lat)
save("work_origins", file = "data-inputs/Travel-Time-Calculations/inputs/work_origins.Rdata")
save("job_destinations", file = "data-inputs/Travel-Time-Calculations/inputs/job_destinations.Rdata")
# set up batching according to how many origin rows to process at one time
chunksize = 50
num_chunks = ceiling(nrow(work_origins)/chunksize)
# create origin-destination pairs
origins_chunks <- as.disk.frame(work_origins,
outdir = "data-inputs/Travel-Time-Calculations/df/Orig",
nchunks = num_chunks,
overwrite = TRUE)
start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)
for (i in 1:num_chunks){
Orig_chunk <- get_chunk(origins_chunks, i)
ttm_chunk <- travel_time_matrix(r5r_core = r5_ONT,
origins = Orig_chunk,
destinations = job_destinations,
mode = c("CAR"),
departure_datetime = as.POSIXct(strptime("2021-10-20 07:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
max_trip_duration = 180)
# export output as disk.frame
ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
nchunks = 1,
outdir = "data-inputs/Travel-Time-Calculations/df/output_ttm",
compress = 50,
overwrite = TRUE),
add_chunk(output_df, ttm_chunk, chunk_id = i))
setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
print(paste0("OD matrix calculation took ", round(difftime(end.time, start.time, units = "mins"), digits = 2), " minutes..."))
output_OD_car1 <- as.data.frame(output_df)
save("output_OD_car1", file = "data-inputs/Travel-Time-Calculations/results/output_OD_car1.Rdata")
save("output_OD_car1", file = "data-inputs/Travel-Time-Calculations/results/output_OD_car1.Rdata")
